// ============ é…ç½®å¼€å…³ ============
const USE_MOCK = false;  // true = ä½¿ç”¨ Mock æ•°æ®, false = ä½¿ç”¨ Native Host
// ==================================

const HOST_NAME = "feedly.ai.overlay";
const CACHE_TTL_MS = 30 * 1000;
const cache = new Map();

// Default settings for summary API
const DEFAULT_SETTINGS = {
  apiEndpoint: 'https://api.openai.com/v1',
  apiKey: '',
  model: 'gpt-4o-mini',
  summaryPrompt: `ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å†…å®¹åˆ†æžä¸“å®¶ã€‚è¯·å¯¹ä»¥ä¸‹æ–‡ç« è¿›è¡Œå…¨é¢ã€è¯¦ç»†çš„æ€»ç»“ã€‚

é‡è¦æç¤ºï¼šä¸è¦åªå†™ç®€çŸ­æ¦‚è¿°ï¼Œè€Œæ˜¯è¦æ·±å…¥åˆ†æžå¹¶æ€»ç»“æ–‡ç« ä¸­çš„æ‰€æœ‰å…³é”®è¦ç‚¹ã€‚

è¯·æŒ‰ä»¥ä¸‹ç»“æž„ç»„ç»‡ä½ çš„å›žç­”ï¼š

## ðŸŽ¯ æ ¸å¿ƒè§‚ç‚¹
ç”¨2-3å¥è¯æ¸…æ™°é™ˆè¿°æ–‡ç« çš„ä¸»è¦è®ºç‚¹ã€äº‹ä»¶æˆ–æ ¸å¿ƒè§‚ç‚¹ã€‚

## ðŸ”‘ å…³é”®è¦ç‚¹ä¸Žç»†èŠ‚
è¯¦ç»†åˆ—å‡ºæ–‡ç« ä¸­çš„æ‰€æœ‰é‡è¦å†…å®¹ï¼š
- åŒ…å«å…·ä½“çš„äº‹å®žã€æ•°æ®ã€ç»Ÿè®¡ä¿¡æ¯
- æ¶µç›–æ–‡ç« çš„æ‰€æœ‰ä¸»è¦ç« èŠ‚å’Œè®ºç‚¹
- è®°å½•é‡è¦çš„å¼•ç”¨æˆ–å£°æ˜Ž
- å¦‚æœ‰æŠ€æœ¯ç»†èŠ‚ï¼Œè¯·è¯¦ç»†è¯´æ˜Ž

## ðŸ’¡ åˆ†æžä¸Žå¯ç¤º
- è¿™å¯¹è¯»è€…æ„å‘³ç€ä»€ä¹ˆï¼Ÿ
- æœ‰å“ªäº›æ›´å¹¿æ³›çš„å½±å“ï¼Ÿ
- æ–‡ç« å¾—å‡ºäº†ä»€ä¹ˆç»“è®ºæˆ–é¢„æµ‹ï¼Ÿ

## ðŸ“ è¡¥å……è¯´æ˜Ž
- æ–‡ç« ä¸­æåˆ°çš„ä»»ä½•æ³¨æ„äº‹é¡¹ã€å±€é™æ€§æˆ–åé¢è§‚ç‚¹
- ç›¸å…³èƒŒæ™¯ä¿¡æ¯æˆ–ä¸Šä¸‹æ–‡

è¯·ä½¿ç”¨æ¸…æ™°ç®€æ´çš„è¯­è¨€ï¼Œç”¨è¦ç‚¹åˆ—è¡¨æé«˜å¯è¯»æ€§ã€‚ç›®æ ‡æ˜¯æä¾›ä¸€ä»½èƒ½å¤Ÿæ•æ‰æ–‡ç« å®Œæ•´æ·±åº¦çš„è¯¦å°½æ€»ç»“ã€‚`
};

// Get settings from storage
async function getSettings() {
  return new Promise((resolve) => {
    chrome.storage.sync.get(DEFAULT_SETTINGS, (items) => {
      resolve(items);
    });
  });
}

// Call OpenAI-compatible API directly
async function callOpenAI(content, title) {
  const settings = await getSettings();

  if (!settings.apiKey) {
    return { error: 'API key not configured. Please set it in extension options.' };
  }

  if (!content || content.length < 50) {
    return { error: 'Article content is empty or too short to summarize.' };
  }

  const endpoint = settings.apiEndpoint.replace(/\/$/, '') + '/chat/completions';

  try {
    console.log(`[Feedly AI] Calling OpenAI API with ${content.length} chars of content`);

    const response = await fetch(endpoint, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${settings.apiKey}`
      },
      body: JSON.stringify({
        model: settings.model,
        messages: [
          { role: 'system', content: settings.summaryPrompt },
          { role: 'user', content: `æ–‡ç« æ ‡é¢˜: ${title}\n\næ–‡ç« å†…å®¹:\n\n${content}` }
        ],
        temperature: 0.5
      })
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('OpenAI API error:', response.status, errorText);
      return { error: `API error: ${response.status} - ${errorText.substring(0, 200)}` };
    }

    const data = await response.json();
    const summary = data.choices?.[0]?.message?.content;

    if (!summary) {
      return { error: 'No content in API response' };
    }

    return { summary };
  } catch (err) {
    console.error('OpenAI API call failed:', err);
    return { error: `Request failed: ${err.message}` };
  }
}

// Fetch article content from URL
async function fetchArticleContent(url) {
  try {
    console.log(`[Feedly AI] Fetching article content from: ${url}`);

    const response = await fetch(url, {
      headers: {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
      }
    });

    if (!response.ok) {
      console.error(`Fetch failed: ${response.status}`);
      return null;
    }

    const html = await response.text();

    // Extract text content from HTML (simple approach)
    const parser = new DOMParser();
    const doc = parser.parseFromString(html, 'text/html');

    // Remove script, style, nav, header, footer elements
    const removeSelectors = ['script', 'style', 'nav', 'header', 'footer', 'aside', '.sidebar', '.comments', '.advertisement'];
    removeSelectors.forEach(sel => {
      doc.querySelectorAll(sel).forEach(el => el.remove());
    });

    // Try to find main content
    const contentSelectors = ['article', '.article', '.post-content', '.entry-content', '.content', 'main', '.main'];
    let content = '';

    for (const sel of contentSelectors) {
      const el = doc.querySelector(sel);
      if (el && el.innerText.length > 200) {
        content = el.innerText;
        break;
      }
    }

    // Fallback to body
    if (!content || content.length < 200) {
      content = doc.body?.innerText || '';
    }

    // Clean up whitespace
    content = content.replace(/\s+/g, ' ').trim();

    console.log(`[Feedly AI] Fetched ${content.length} chars of content`);
    return content;
  } catch (err) {
    console.error('Fetch article failed:', err);
    return null;
  }
}

// Mock æ•°æ®ï¼šæ¨¡æ‹Ÿ Native Host è¿”å›žçš„è¯„åˆ†
function getMockScores(ids) {
  const items = {};
  for (const id of ids) {
    const score = Math.round((Math.random() * 2 + 3) * 10) / 10; // 3.0 - 5.0
    const verdicts = ["å€¼å¾—é˜…è¯»", "ä¸€èˆ¬ï¼Œå¯é€‰", "ä¸å€¼å¾—è¯»"];
    const verdict = score >= 4 ? verdicts[0] : score >= 3 ? verdicts[1] : verdicts[2];

    items[id] = {
      id: id,
      score: score,
      data: {
        verdict: verdict,
        summary: "è¿™æ˜¯ä¸€ç¯‡å…³äºŽæŠ€æœ¯çš„æ–‡ç« ï¼Œå†…å®¹æ¶‰åŠå‰æ²¿å¼€å‘å®žè·µã€‚",
        reason: `AIè¯„åˆ†: ${score}/5.0 - ${verdict}`
      },
      updated_at: new Date().toISOString(),
      found: true
    };
  }
  return items;
}

// Native Host é€šä¿¡
function sendNativeMessage(payload) {
  return new Promise((resolve) => {
    chrome.runtime.sendNativeMessage(HOST_NAME, payload, (response) => {
      if (chrome.runtime.lastError) {
        console.error("Native messaging error:", chrome.runtime.lastError.message);
        resolve({ error: chrome.runtime.lastError.message });
        return;
      }
      resolve(response || {});
    });
  });
}

function getCached(ids) {
  const now = Date.now();
  const items = {};
  const missing = [];
  for (const id of ids) {
    const cached = cache.get(id);
    if (cached && now - cached.ts < CACHE_TTL_MS) {
      items[id] = cached.value;
    } else {
      missing.push(id);
    }
  }
  return { items, missing };
}

function mergeCache(items) {
  const ts = Date.now();
  for (const [id, value] of Object.entries(items)) {
    cache.set(id, { ts, value });
  }
}

chrome.runtime.onMessage.addListener((msg, sender, sendResponse) => {
  console.log("Background received message:", msg);

  if (!msg || msg.type !== "get_scores") {
    return;
  }

  // Support both old (ids array) and new (items array) formats
  let ids = [];
  let itemsMap = new Map();

  if (msg.items && Array.isArray(msg.items)) {
      ids = msg.items.map(i => i.id);
      msg.items.forEach(i => itemsMap.set(i.id, i));
  } else {
      ids = Array.isArray(msg.ids) ? msg.ids : [];
  }

  console.log("Processing get_scores for", ids.length, "articles");

  if (ids.length === 0) {
    sendResponse({ items: {} });
    return;
  }

  const { items, missing } = getCached(ids);
  if (missing.length === 0) {
    console.log("All from cache");
    sendResponse({ items });
    return;
  }

  if (USE_MOCK) {
    // Mock æ¨¡å¼
    console.log("[MOCK MODE] Generating mock scores for", missing.length, "articles");
    const fetched = getMockScores(missing);
    mergeCache(fetched);
    sendResponse({ items: { ...items, ...fetched } });
  } else {
    // Native Host æ¨¡å¼
    console.log("[NATIVE MODE] Fetching scores from Native Host for", missing.length, "articles");

    // Construct items list for native host, including metadata if available
    const missingItems = missing.map(id => itemsMap.get(id) || { id: id });

    sendNativeMessage({ type: "get_scores", items: missingItems }).then((resp) => {
      console.log("Native Host Response:", JSON.stringify(resp, null, 2));
      const fetched = resp && resp.items ? resp.items : {};
      mergeCache(fetched);
      sendResponse({ items: { ...items, ...fetched } });
    });
  }

  return true;
});

chrome.runtime.onMessage.addListener((msg, sender, sendResponse) => {
  if (!msg || msg.type !== "analyze_article") {
    return;
  }

  console.log("Processing analyze_article for", msg.id);

  if (USE_MOCK) {
     // Mock analysis
     setTimeout(() => {
         const score = 4.5;
         const verdict = "å€¼å¾—é˜…è¯»";
         const result = {
             id: msg.id,
             score: score,
             data: {
                 verdict: verdict,
                 summary: "è¿™æ˜¯å®žæ—¶åˆ†æžçš„Mockç»“æžœã€‚",
                 reason: `å®žæ—¶AIè¯„åˆ†: ${score}/5.0 - ${verdict}`
             },
             found: true
         };
         mergeCache({[msg.id]: result});
         sendResponse(result);
     }, 1500);
  } else {
      sendNativeMessage(msg).then(resp => {
          console.log("Native Analysis Response:", resp);
          if (resp && !resp.error) {
              mergeCache({[msg.id]: resp});
          }
          sendResponse(resp);
      });
  }
  return true;
});

chrome.runtime.onMessage.addListener((msg, sender, sendResponse) => {
  if (!msg || msg.type !== "summarize_article") {
    return;
  }

  console.log("Processing summarize_article for", msg.id);
  console.log("Content length:", msg.content?.length || 0, "URL:", msg.url);

  if (USE_MOCK) {
      setTimeout(() => {
          sendResponse({
              id: msg.id,
              summary: "## Mock Summary\n\n- Point 1: This is a mock summary point.\n- Point 2: Another key detail from the article.\n- Conclusion: This is a test conclusion."
          });
      }, 1500);
  } else {
      // If content is too short, try to fetch from URL first
      (async () => {
          let content = msg.content || '';

          if (content.length < 100 && msg.url) {
              console.log('[Feedly AI] Content too short, fetching from URL...');
              const fetched = await fetchArticleContent(msg.url);
              if (fetched && fetched.length > content.length) {
                  content = fetched;
              }
          }

          const result = await callOpenAI(content, msg.title);
          console.log("OpenAI Summarize Response:", result);
          sendResponse({
              id: msg.id,
              summary: result.summary || result.error
          });
      })();
  }
  return true;
});

console.log(`Feedly AI Overlay background script loaded (${USE_MOCK ? 'MOCK' : 'NATIVE'} MODE)`);
